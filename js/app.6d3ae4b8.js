(function(){"use strict";var e={143:function(e,t,i){var l=i(963),n=i(465),a=(i(415),i(146)),s=i(252);function o(e,t){const i=(0,s.up)("router-view");return(0,s.wg)(),(0,s.j4)(i)}var r=i(744);const u={},d=(0,r.Z)(u,[["render",o]]);var f=d,c=i(201);const m=e=>((0,s.dD)("data-v-0c25bd70"),e=e(),(0,s.Cn)(),e),h={class:"home"},p={class:"common-layout"},g=m((()=>(0,s._)("h1",{id:"Milestone 2 For CSE 274"},"Milestone 2 For CSE 274",-1))),w=m((()=>(0,s._)("h2",{id:"1. Introduction"},"1. Introduction",-1))),y=m((()=>(0,s._)("p",{style:{"text-align":"left"}},[(0,s.Uk)(" In this project, I implemented a realtime ray tracing denoiser, including techniques like AAF (axis aligned filter) and MAAF (multiple axis aligned filter). The implementation is based on Vulkan ray tracing extension, integrated into my personal toy engine project "),(0,s._)("a",{href:"https://github.com/SuikaSibyl/SIByLEngine2022"}," SIByL Engine"),(0,s.Uk)(". ")],-1))),b=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Essentially, in this project I re-implement some papers: ",-1))),_=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"http://graphics.berkeley.edu/papers/UdayMehta-AAF-2012-12/"}," Axis-Aligned Filtering for Interactive Sampled Soft Shadows ")],-1))),v=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"https://cseweb.ucsd.edu/~ravir/filtering_GI_final.pdf"}," Axis-Aligned Filtering for Interactive Physically-Based Diffuse Indirect Lighting ")],-1))),x=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"https://cseweb.ucsd.edu/~ravir/paper_maaf.pdf"}," Multiple Axis-Aligned Filters for Rendering of Combined Distribution Effects ")],-1))),k=m((()=>(0,s._)("p",{style:{"text-align":"left"}},[(0,s._)("br"),(0,s.Uk)(" And some closely related papers are: ")],-1))),A=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"https://cseweb.ucsd.edu//~ravir/aaf.pdf"}," Factored Axis-Aligned Filtering for Rendering Multiple Distribution Effects ")],-1))),W=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"https://dl.acm.org/doi/pdf/10.1145/2816814"}," Fast 4D Sheared Filtering for Interactive Rendering of Distribution Effects ")],-1))),j=m((()=>(0,s._)("br",null,null,-1))),I=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Implementation is only compatible with Windows OS and Nvidia RTX GPU. All the results are run and measuredon my personal RTX 3070 laptop. ",-1))),F=m((()=>(0,s._)("h2",{id:"2. Implementation"},"2. Implementation Theory",-1))),S=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Here is a summary of commons and differences of all these related works, using different filters and handling different distribution effects: ",-1))),U=m((()=>(0,s._)("h3",{id:"2.1. inisamp"},"2.1 Initial Sampling & Frequency Domain Slope",-1))),T=m((()=>(0,s._)("br",null,null,-1))),P=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," The 2D f(x,y) term we are interested in, is turned out to be a shear shape in primal domain and a line in Fourier domain. If there are more than one (or not parallel) frequency resource, there would be multiple lines and form a double wedge shape. ",-1))),M={style:{"text-align":"left"}},C=m((()=>(0,s._)("strong",null,"Soft Shadow:",-1))),E=m((()=>(0,s._)("code",null,"d1",-1))),D=m((()=>(0,s._)("code",null,"d2_min",-1))),G=m((()=>(0,s._)("code",null,"d2_max",-1))),O={style:{"text-align":"left"}},B=m((()=>(0,s._)("strong",null,"Global Illumination:",-1))),R=m((()=>(0,s._)("code",null,"z",-1))),q={style:{"text-align":"left"}},L=m((()=>(0,s._)("strong",null,"Defocus Blur:",-1))),z=m((()=>(0,s._)("code",null,"z",-1))),H=m((()=>(0,s._)("code",null,"v",-1))),N=m((()=>(0,s._)("code",null,"F",-1))),X=m((()=>(0,s._)("code",null,"S",-1))),Z=m((()=>(0,s._)("li",{style:{"text-align":"left"}},[(0,s._)("strong",null,"Motion Blur:"),(0,s.Uk)(" May be included later. ")],-1))),V=m((()=>(0,s._)("h3",{id:"2.2. bound"},"2.2 Bandlimiters",-1))),Y=m((()=>(0,s._)("br",null,null,-1))),J=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," The 2D f(x,y) term we are interested in are double-wedge in Fourier space, but they are not bandlimited. But no worries because they are all found to be filtered by some hero bandlimiter h(y) terms along the y axis, introducing low-pass bandlimiting. ",-1))),K=m((()=>(0,s._)("li",{style:{"text-align":"left"}},[(0,s._)("strong",null,"Soft Shadow:"),(0,s.Uk)(" In y axis, the "),(0,s._)("code",null,"visibility"),(0,s.Uk)(" term is convoluted and bandlimited by "),(0,s._)("code",null,"light intensity"),(0,s.Uk)(", which is assumed to be a Guassian function. ")],-1))),Q=m((()=>(0,s._)("li",{style:{"text-align":"left"}},[(0,s._)("strong",null,"Global Illumination:"),(0,s.Uk)(" In y axis, the "),(0,s._)("code",null,"Li"),(0,s.Uk)(" term is convoluted and bandlimited by "),(0,s._)("code",null,"transfer"),(0,s.Uk)(" function, which is not a Gaussian function but could also bring low-pass effects (consider how high-frequency lights are blurred in diffuse surface, like we can present them just using order 3 SH). ")],-1))),$=m((()=>(0,s._)("li",{style:{"text-align":"left"}},[(0,s._)("strong",null,"Defocus Blur:"),(0,s.Uk)(" In y axis, the "),(0,s._)("code",null,"Le"),(0,s.Uk)(" term is convoluted and bandlimited by "),(0,s._)("code",null,"aperture function"),(0,s.Uk)(", which is also assumed to be a Gaussian function. (Although I think noramlly it should be a const, but normally we also use uniform area light, so just tolerant these assumptions anyway...) ")],-1))),ee=m((()=>(0,s._)("li",{style:{"text-align":"left"}},[(0,s._)("strong",null,"Motion Blur:"),(0,s.Uk)(" In y axis, the "),(0,s._)("code",null,"Le"),(0,s.Uk)(" term is convoluted and bandlimited by "),(0,s._)("code",null,"shutter response"),(0,s.Uk)(" function, which is also again assumed to be a Gaussian function. ")],-1))),te=m((()=>(0,s._)("br",null,null,-1))),ie=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," And actually we could notice the truth that, we need not bother to compute the bandlimiting in y, because it is just given. It is about area light size, brdf of surface, lens, shutter. And in AAF, it does not even use an extra gaussian in y axis when do Monte Carlo integral, as the h term iteself is the one who introduce the bandlimiting in axis-aligned filter. ",-1))),le=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," The interesting thing is that, when we do MAAF, we no longer include the h term. I think it is an essential insight that, MAAF actually somewhat decompose the h term into several parts with different frequency, and reconstruct them individually and finally modulate them back agian. ",-1))),ne=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," For example in GI case, we are decomposing diffuse transfer function. First imitate some kind of super-diffuse surface, where we get a larger image space filter to better remove the noise. And then imitate some kind of detail filter to extract all details and use small image space filter to preserve necessary details. ",-1))),ae=m((()=>(0,s._)("p",{style:{"text-align":"left"}},[(0,s.Uk)(" The "),(0,s._)("code",null,"decomposing brdf/transfer function"),(0,s.Uk)(" part is where I think is really cool. Maybe we could do more things about it? I don't now. ")],-1))),se=m((()=>(0,s._)("h3",{id:"2.3. advantages"},"2.3 Taking Advantages of Bandlimits",-1))),oe=m((()=>(0,s._)("br",null,null,-1))),re=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," In AAF, we do not explicitly do y axis filtering as the h term itself is already the filter we want. But it does screen-space filtering (in x dim). Therefore, it is necessary to know x bandlimiting. It actually comes from two parts: 1. pixel limits the useful freqeuncy, higher frequency would do no good and even introduce aliasing. 2. as given the double-wedge shape, bandlimits in y actually also bring bandlimits in x. ",-1))),ue=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Given that, we can compute the screen space filter size beta. The GI case with Cornell Box scene is shown below. We can see that in corners, we do less filtering, and in flat and wide positions we do more blur. It is consistent with our intuition, because in corners there are very near reflectors who introduce high frequency details. ",-1))),de=m((()=>(0,s._)("br",null,null,-1))),fe=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"beta (Gaussian standard deviation) for indirect illumination")],-1))),ce=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Also, given bandlimits of x and y, we can compute the required sampling rate of a certain packing strategy, and derive the adaptive SPP. Therefore areas with loose bandlimiting are going to have higher SPP, which is of course correct in frequency analysis. So the logic is, we sample more samples in places with more details, and actually places with more details are likely to have higher variance, so we are placing more samples to reduce variance. ",-1))),me=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"adaptive ssp computed in cornell box for indirect illumination")],-1))),he=m((()=>(0,s._)("h2",{id:"3. Results"},"3. Results",-1))),pe=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Here are some of our results. Notice that all the results are run and measured on my personal RTX 3070 Laptop device. Framebuffer sizes are fixed to 800 X 600 pixels. ",-1))),ge=m((()=>(0,s._)("h3",{id:"3.1. aafss"},"3.1 AAF Soft Shadow",-1))),we=m((()=>(0,s._)("br",null,null,-1))),ye=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"I implemented AAF based soft sahdow accroding to the paper: ",-1))),be=m((()=>(0,s._)("p",{style:{"text-align":"center"}},[(0,s._)("a",{href:"http://graphics.berkeley.edu/papers/UdayMehta-AAF-2012-12/"}," Axis-Aligned Filtering for Interactive Sampled Soft Shadows ")],-1))),_e=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"In our implementation, we estimate direct illumination as point light (as the original work and related works do, to ensure direct light part is not noisy). And we trace one primary ray with 9 shadow rays stratified on light source. Later, we also do up to 84 adaptive continue samples. Especially, we adopt a slope blur pass, before adaptive sampling, to remove some outliner points who failed to find any unoccluded path. We actually use max operator instead average which is mentioned in the paper. ",-1))),ve=m((()=>(0,s._)("div",{id:"ssUnfiltFilt"},null,-1))),xe=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: initial sample results | right: filtered result")],-1))),ke=m((()=>(0,s._)("div",{id:"ssFiltGT"},null,-1))),Ae=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: filtered result | right: ground truth")],-1))),We=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple-light"},null,-1))),je=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple"},null,-1))),Ie=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"We can run AAF Soft Shadow in realtime with 300fps in 800X600. We use different random seed per frame and still get robust result without significant temporal anliasing. Here is a demo with animation: ",-1))),Fe=m((()=>(0,s._)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/jfqbPddvzgI",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1))),Se=m((()=>(0,s._)("h3",{id:"3.2. aafgi"},"3.2 AAF Global Illumination",-1))),Ue=m((()=>(0,s._)("br",null,null,-1))),Te=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"I implemented AAF based diffuse global illumination accroding to the paper: ",-1))),Pe=m((()=>(0,s._)("p",{style:{"text-align":"center"}},[(0,s._)("a",{href:"https://cseweb.ucsd.edu/~ravir/filtering_GI_final.pdf"}," Axis-Aligned Filtering for Interactive Physically-Based Diffuse Indirect Lighting ")],-1))),Me=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"In our implementation, we use one bounce indirect lighting, 16 stratified initial samples and up to 84 adaptive continue samples for global illumination. No slope blur, and only do adaptive filtering on indirect light, which is later combined with direct light (use next event estimation). ",-1))),Ce=m((()=>(0,s._)("div",{id:"giUnfiltFilt"},null,-1))),Ee=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: initial sample results | right: filtered result")],-1))),De=m((()=>(0,s._)("div",{id:"giFiltGT"},null,-1))),Ge=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: filtered result | right: ground truth")],-1))),Oe=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple-light"},null,-1))),Be=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple"},null,-1))),Re=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"We can run AAF GI in realtime with 60fps in 800X600. Again, we use different random seed per frame and get robust result without significant temporal anliasing. Here is a demo with animation: ",-1))),qe=m((()=>(0,s._)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/U79zRqgjwy8",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1))),Le=m((()=>(0,s._)("h3",{id:"3.3. MAAF"},"3.3 MAAF",-1))),ze=m((()=>(0,s._)("br",null,null,-1))),He=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"// TODO ",-1))),Ne=m((()=>(0,s._)("h2",{id:"4. Future Plans"},"4. Future Plans",-1))),Xe=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"There are about 2 more weeks to go, so generally, I am going to try to implement MAAF, especially with multiple effects combination of soft shadow, global illumination and defocs blur. Although I have implemented AAF already, MAAF seems to be somewhat challenging as no realted code is provided and some details are not mentioned in the paper. But anyway I will try to do it. ",-1)));function Ze(e,t,i,l,n,a){const o=(0,s.up)("el-header"),r=(0,s.up)("el-row"),u=(0,s.up)("vue-latex"),d=(0,s.up)("el-image"),f=(0,s.up)("el-col"),c=(0,s.up)("el-main"),m=(0,s.up)("el-divider"),Ze=(0,s.up)("el-link"),Ve=(0,s.up)("el-footer"),Ye=(0,s.up)("el-container");return(0,s.wg)(),(0,s.iD)("div",h,[(0,s._)("div",p,[(0,s.Wm)(Ye,null,{default:(0,s.w5)((()=>[(0,s.Wm)(o,null,{default:(0,s.w5)((()=>[g])),_:1}),(0,s.Wm)(Ye,null,{default:(0,s.w5)((()=>[(0,s.Wm)(Ye,null,{default:(0,s.w5)((()=>[(0,s.Wm)(c,null,{default:(0,s.w5)((()=>[(0,s.Wm)(r,{class:"row-bg"},{default:(0,s.w5)((()=>[w,y,b])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[_,v,x])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[k])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[A,W])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[j,I])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[F,S,(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[U,T])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[P,(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[(0,s._)("li",M,[C,(0,s.Uk)(" For each primary ray shading point, find the distance to light (center) "),E,(0,s.Uk)(". Then emit 9 shadow ray from the shading point, who are stratified distributed on the light surface, collecting the minimum and maximum distance from light to any occluder along the ray, "),D,(0,s.Uk)(" and "),G,(0,s.Uk)(". The Fourier space slope is: "),(0,s.Wm)(u,{expression:"s=d_1/d_2-1","display-mode":""})]),(0,s._)("li",O,[B,(0,s.Uk)(" For each primary ray, emit 16 secondary rays from the shading point stratified distributed on the hemisphere, collecting the minimum and maximum distance "),R,(0,s.Uk)(" from shading point to any reflector. The Fourier space slope is: "),(0,s.Wm)(u,{expression:"s=z","display-mode":""})]),(0,s._)("li",q,[L,(0,s.Uk)(" Trace multiple primary rays on the lens, collecting the minimum and maximum depth "),z,(0,s.Uk)(" of any hit objects. Also given the half-width of the image in pixels "),H,(0,s.Uk)(", the focal distance "),N,(0,s.Uk)(", the size of the focal plane "),X,(0,s.Uk)(". The Fourier space slope is: "),(0,s.Wm)(u,{expression:"s=\\frac{V}{S}(\\frac{F}{z}-1)","display-mode":""},null,8,["expression"])]),Z])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[V,Y])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[J,(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[K,Q,$,ee])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[te,ie,le,ne,ae])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[se,oe])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[re,ue])),_:1}),de,(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[(0,s.Wm)(d,{style:{width:"400px",height:"300px"},src:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/gi-betta-cornellbox.png",fit:"fill"}),fe])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[ce])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[(0,s.Wm)(d,{style:{width:"400px",height:"300px"},src:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/spp-gi-cornellbox.png",fit:"fill"}),me])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[he,pe])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[ge,we])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[ye])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[be])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[_e])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[(0,s.Wm)(f,{span:e.auto},{default:(0,s.w5)((()=>[ve,xe,ke,Ae])),_:1},8,["span"]),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[We])),_:1}),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[je])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Ie])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[Fe])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Se,Ue])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Te])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[Pe])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Me])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[(0,s.Wm)(f,{span:e.auto},{default:(0,s.w5)((()=>[Ce,Ee,De,Ge])),_:1},8,["span"]),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[Oe])),_:1}),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[Be])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Re])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[qe])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Le,ze])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[He])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Ne,Xe])),_:1})])),_:1}),(0,s.Wm)(m),(0,s.Wm)(Ve,null,{default:(0,s.w5)((()=>[(0,s.Wm)(Ze,{href:"https://suikasibyl.github.io/",target:"_blank",type:"primary"},{default:(0,s.w5)((()=>[(0,s.Uk)("My Homepage")])),_:1})])),_:1})])),_:1})])),_:1})])),_:1})])])}var Ve=i(194),Ye=i.n(Ve),Je={name:"HomeView",mounted(){new(Ye())({el:"#ssUnfiltFilt",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-noisy-softshadow-grids.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-filtered-softshadow-grids.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(Ye())({el:"#ssFiltGT",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-filtered-softshadow-grids.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-benchmark-softshadow-grids.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(Ye())({el:"#giUnfiltFilt",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-noisy-gi-cornellbox.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-filtered-gi-cornellbox.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(Ye())({el:"#giFiltGT",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-filtered-gi-cornellbox.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-benchmark-gi-cornellbox.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"})}};const Ke=(0,r.Z)(Je,[["render",Ze],["__scopeId","data-v-0c25bd70"]]);var Qe=Ke;const $e=[{path:"/CSE274-RealtimeDenoiser-WebPage/cse274-realtime-denoiser",name:"home",component:Qe},{path:"/CSE274-RealtimeDenoiser-WebPage/about",name:"about",component:()=>i.e(443).then(i.bind(i,381))},{path:"/CSE274-RealtimeDenoiser-WebPage",redirect:"/CSE274-RealtimeDenoiser-WebPage/cse274-realtime-denoiser"},{path:"/",redirect:"/CSE274-RealtimeDenoiser-WebPage/cse274-realtime-denoiser"}],et=(0,c.p7)({history:(0,c.PO)(""),routes:$e});var tt=et;const it=(0,l.ri)(f);it.use(tt).mount("#app"),it.use(n.Z),it.use(a.ZP)}},t={};function i(l){var n=t[l];if(void 0!==n)return n.exports;var a=t[l]={exports:{}};return e[l].call(a.exports,a,a.exports,i),a.exports}i.m=e,function(){var e=[];i.O=function(t,l,n,a){if(!l){var s=1/0;for(d=0;d<e.length;d++){l=e[d][0],n=e[d][1],a=e[d][2];for(var o=!0,r=0;r<l.length;r++)(!1&a||s>=a)&&Object.keys(i.O).every((function(e){return i.O[e](l[r])}))?l.splice(r--,1):(o=!1,a<s&&(s=a));if(o){e.splice(d--,1);var u=n();void 0!==u&&(t=u)}}return t}a=a||0;for(var d=e.length;d>0&&e[d-1][2]>a;d--)e[d]=e[d-1];e[d]=[l,n,a]}}(),function(){i.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return i.d(t,{a:t}),t}}(),function(){i.d=function(e,t){for(var l in t)i.o(t,l)&&!i.o(e,l)&&Object.defineProperty(e,l,{enumerable:!0,get:t[l]})}}(),function(){i.f={},i.e=function(e){return Promise.all(Object.keys(i.f).reduce((function(t,l){return i.f[l](e,t),t}),[]))}}(),function(){i.u=function(e){return"js/about.a269fb9f.js"}}(),function(){i.miniCssF=function(e){}}(),function(){i.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"===typeof window)return window}}()}(),function(){i.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)}}(),function(){var e={},t="cse274:";i.l=function(l,n,a,s){if(e[l])e[l].push(n);else{var o,r;if(void 0!==a)for(var u=document.getElementsByTagName("script"),d=0;d<u.length;d++){var f=u[d];if(f.getAttribute("src")==l||f.getAttribute("data-webpack")==t+a){o=f;break}}o||(r=!0,o=document.createElement("script"),o.charset="utf-8",o.timeout=120,i.nc&&o.setAttribute("nonce",i.nc),o.setAttribute("data-webpack",t+a),o.src=l),e[l]=[n];var c=function(t,i){o.onerror=o.onload=null,clearTimeout(m);var n=e[l];if(delete e[l],o.parentNode&&o.parentNode.removeChild(o),n&&n.forEach((function(e){return e(i)})),t)return t(i)},m=setTimeout(c.bind(null,void 0,{type:"timeout",target:o}),12e4);o.onerror=c.bind(null,o.onerror),o.onload=c.bind(null,o.onload),r&&document.head.appendChild(o)}}}(),function(){i.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})}}(),function(){i.p=""}(),function(){var e={143:0};i.f.j=function(t,l){var n=i.o(e,t)?e[t]:void 0;if(0!==n)if(n)l.push(n[2]);else{var a=new Promise((function(i,l){n=e[t]=[i,l]}));l.push(n[2]=a);var s=i.p+i.u(t),o=new Error,r=function(l){if(i.o(e,t)&&(n=e[t],0!==n&&(e[t]=void 0),n)){var a=l&&("load"===l.type?"missing":l.type),s=l&&l.target&&l.target.src;o.message="Loading chunk "+t+" failed.\n("+a+": "+s+")",o.name="ChunkLoadError",o.type=a,o.request=s,n[1](o)}};i.l(s,r,"chunk-"+t,t)}},i.O.j=function(t){return 0===e[t]};var t=function(t,l){var n,a,s=l[0],o=l[1],r=l[2],u=0;if(s.some((function(t){return 0!==e[t]}))){for(n in o)i.o(o,n)&&(i.m[n]=o[n]);if(r)var d=r(i)}for(t&&t(l);u<s.length;u++)a=s[u],i.o(e,a)&&e[a]&&e[a][0](),e[a]=0;return i.O(d)},l=self["webpackChunkcse274"]=self["webpackChunkcse274"]||[];l.forEach(t.bind(null,0)),l.push=t.bind(null,l.push.bind(l))}();var l=i.O(void 0,[998],(function(){return i(143)}));l=i.O(l)})();
//# sourceMappingURL=app.6d3ae4b8.js.map