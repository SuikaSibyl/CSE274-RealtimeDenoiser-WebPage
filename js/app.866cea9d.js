(function(){"use strict";var e={943:function(e,t,i){var l=i(963),n=i(465),a=(i(415),i(146)),s=i(252);function o(e,t){const i=(0,s.up)("router-view");return(0,s.wg)(),(0,s.j4)(i)}var r=i(744);const u={},d=(0,r.Z)(u,[["render",o]]);var f=d,c=i(201);const m=e=>((0,s.dD)("data-v-8a92362a"),e=e(),(0,s.Cn)(),e),h={class:"home"},p={class:"common-layout"},g=m((()=>(0,s._)("h1",{id:"Report For CSE 274"},"A Priori Frequency Analysis Based Denoiser",-1))),w=m((()=>(0,s._)("h2",{id:"1. Introduction"},"1. Introduction",-1))),y=m((()=>(0,s._)("p",{style:{"text-align":"left"}},[(0,s.Uk)(" In this project, I implemented a realtime ray tracing denoiser, including techniques like AAF (axis aligned filter) and MAAF (multiple axis aligned filter). The implementation is based on Vulkan ray tracing extension, integrated into my personal toy engine project "),(0,s._)("a",{href:"https://github.com/SuikaSibyl/SIByLEngine2022"}," SIByL Engine"),(0,s.Uk)(". ")],-1))),b=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Essentially, in this project I re-implement some papers: ",-1))),_=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"http://graphics.berkeley.edu/papers/UdayMehta-AAF-2012-12/"}," Axis-Aligned Filtering for Interactive Sampled Soft Shadows ")],-1))),v=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"https://cseweb.ucsd.edu/~ravir/filtering_GI_final.pdf"}," Axis-Aligned Filtering for Interactive Physically-Based Diffuse Indirect Lighting ")],-1))),x=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"https://cseweb.ucsd.edu/~ravir/paper_maaf.pdf"}," Multiple Axis-Aligned Filters for Rendering of Combined Distribution Effects ")],-1))),A=m((()=>(0,s._)("p",{style:{"text-align":"left"}},[(0,s._)("br"),(0,s.Uk)(" And some closely related papers (will be talked about) are: ")],-1))),k=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"https://cseweb.ucsd.edu//~ravir/aaf.pdf"}," Factored Axis-Aligned Filtering for Rendering Multiple Distribution Effects ")],-1))),W=m((()=>(0,s._)("li",null,[(0,s._)("a",{href:"https://dl.acm.org/doi/pdf/10.1145/2816814"}," Fast 4D Sheared Filtering for Interactive Rendering of Distribution Effects ")],-1))),F=m((()=>(0,s._)("br",null,null,-1))),j=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Implementation is only compatible with Windows OS and Nvidia RTX GPU. All the results are run and measured on my personal RTX 3070 laptop. ",-1))),I=m((()=>(0,s._)("h2",{id:"2. Related Work"},"2. Related Work",-1))),S=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Here is a summary of commons and differences of all these related works, using different filters and handling different distribution effects, but all based on local frequency analysis. ",-1))),U=m((()=>(0,s._)("h2",{id:"2. Implementation"},"2. Implementation Theory",-1))),T=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Here is a summary of commons and differences of all these related works, using different filters and handling different distribution effects, but all based on local frequency analysis. ",-1))),C=m((()=>(0,s._)("h3",{id:"2.1. inisamp"},"2.1 Initial Sampling & Frequency Domain Slope",-1))),R=m((()=>(0,s._)("br",null,null,-1))),M=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," The 2D f(x,y) term we are interested in, is turned out to be a shear shape in primal domain and a line in Fourier domain (which is orthogonal). If there are more than one (or not parallel) frequency source, there would be multiple lines and form a double wedge shape. ",-1))),G={style:{"text-align":"left"}},D=m((()=>(0,s._)("strong",null,"Soft Shadow:",-1))),E=m((()=>(0,s._)("code",null,"d1",-1))),P=m((()=>(0,s._)("code",null,"d2",-1))),B={style:{"text-align":"left"}},q=m((()=>(0,s._)("strong",null,"Global Illumination:",-1))),O=m((()=>(0,s._)("code",null,"z",-1))),L={style:{"text-align":"left"}},z=m((()=>(0,s._)("strong",null,"Defocus Blur:",-1))),Y=m((()=>(0,s._)("code",null,"z",-1))),H=m((()=>(0,s._)("code",null,"v",-1))),N=m((()=>(0,s._)("code",null,"F",-1))),X=m((()=>(0,s._)("code",null,"S",-1))),J=m((()=>(0,s._)("br",null,null,-1))),Z={style:{"text-align":"left"}},V=m((()=>(0,s._)("strong",null,"Motion Blur:",-1))),K=m((()=>(0,s._)("code",null,"a",-1))),Q=m((()=>(0,s._)("h3",{id:"2.2. bound"},"2.2 Bandlimiters",-1))),$=m((()=>(0,s._)("br",null,null,-1))),ee=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," The 2D f(x,y) term we are interested in are double-wedge in Fourier space, but they are not bandlimited. But no worries because they are all found to be filtered (convolution in primal domain) by some hero bandlimiter h(y) terms along the y axis, introducing low-pass bandlimiting. ",-1))),te=m((()=>(0,s._)("li",{style:{"text-align":"left"}},[(0,s._)("strong",null,"Soft Shadow:"),(0,s.Uk)(" In y axis, the "),(0,s._)("code",null,"visibility"),(0,s.Uk)(" term is convoluted and bandlimited by "),(0,s._)("code",null,"light intensity"),(0,s.Uk)(", which is assumed to be a Guassian function. ")],-1))),ie=m((()=>(0,s._)("li",{style:{"text-align":"left"}},[(0,s._)("strong",null,"Global Illumination:"),(0,s.Uk)(" In y axis, the "),(0,s._)("code",null,"Li"),(0,s.Uk)(" term is convoluted and bandlimited by "),(0,s._)("code",null,"transfer"),(0,s.Uk)(" function, which is not a Gaussian function but could also bring low-pass effects (consider how high-frequency lights are blurred in diffuse surface, like we can present them just using order 3 SH). ")],-1))),le=m((()=>(0,s._)("li",{style:{"text-align":"left"}},[(0,s._)("strong",null,"Defocus Blur:"),(0,s.Uk)(" In y axis, the "),(0,s._)("code",null,"Le"),(0,s.Uk)(" term is convoluted and bandlimited by "),(0,s._)("code",null,"aperture function"),(0,s.Uk)(", which is also assumed to be a Gaussian function. (Although I think noramlly it should be a const, but normally we also use uniform area light, so just tolerant these assumptions anyway...) ")],-1))),ne=m((()=>(0,s._)("li",{style:{"text-align":"left"}},[(0,s._)("strong",null,"Motion Blur:"),(0,s.Uk)(" In y axis, the "),(0,s._)("code",null,"Le"),(0,s.Uk)(" term is convoluted and bandlimited by "),(0,s._)("code",null,"shutter response"),(0,s.Uk)(" function, which is also again assumed to be a Gaussian function. ")],-1))),ae=m((()=>(0,s._)("h3",{id:"2.3. advantages"},"2.3 Taking Advantages of Bandlimits",-1))),se=m((()=>(0,s._)("br",null,null,-1))),oe=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," In AAF, we do not explicitly do y axis filtering as the h term itself is already the filter we want. But it does screen-space filtering (in x dim). Therefore, it is necessary to know x bandlimiting. It actually comes from two parts: 1. pixel limits the useful freqeuncy, higher frequency would do no good and even introduce aliasing. 2. as given the double-wedge shape, bandlimits in y actually also bring bandlimits in x. ",-1))),re=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Given that, we can compute the screen space filter size beta. The GI case with Cornell Box scene is shown below. We can see that in corners, we do less filtering, and in flat and wide positions we do more blur. It is consistent with our intuition, because in corners there are very near reflectors who introduce high frequency details. ",-1))),ue=m((()=>(0,s._)("br",null,null,-1))),de=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"beta (Gaussian standard deviation) for indirect illumination")],-1))),fe=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Also, given bandlimits of x and y, we can compute the required sampling rate of a certain packing strategy, and derive the adaptive SPP. Therefore areas with loose bandlimiting are going to have higher SPP, which is of course correct in frequency analysis. So the logic is, we sample more samples in places with more details, and actually places with more details are likely to have higher variance, so we are placing more samples to reduce variance. ",-1))),ce=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"adaptive ssp computed in cornell box for indirect illumination")],-1))),me=m((()=>(0,s._)("br",null,null,-1))),he=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," And actually we could notice the truth that, we need not bother to compute the bandlimiting in y, because it is just given. It is about area light size, brdf of surface, lens, shutter. And in AAF, it does not even use an extra gaussian in y axis when do Monte Carlo integral, as the h term iteself is the one who introduce the bandlimiting in axis-aligned filter. ",-1))),pe=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," The interesting thing is that, when we do MAAF, we no longer include the h term. (except for GI where we preserve the diffuse transfer function which is not a Gaussian) I think it is an essential insight that, MAAF actually somewhat decompose the h term into several parts with different frequency, and reconstruct them individually and finally modulate them back agian. ",-1))),ge=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," For example in GI case, we are decomposing diffuse transfer function. First imitate some kind of super-diffuse surface, where we get a larger image space filter to better remove the noise. And then imitate some kind of detail filter to extract all details and use small image space filter to preserve necessary details. ",-1))),we=m((()=>(0,s._)("p",{style:{"text-align":"left"}},[(0,s.Uk)(" The "),(0,s._)("code",null,"decomposing brdf/transfer function"),(0,s.Uk)(" part is where I think is really cool. Maybe we could do more things about it? I don't now. ")],-1))),ye=m((()=>(0,s._)("h2",{id:"3. Results"},"3. Results",-1))),be=m((()=>(0,s._)("p",{style:{"text-align":"left"}}," Here are some of our results. Notice that all the results are run and measured on my personal RTX 3070 Laptop device. Framebuffer sizes are fixed to 800 X 600 pixels. ",-1))),_e=m((()=>(0,s._)("h3",{id:"3.1. aafss"},"3.1 AAF Soft Shadow",-1))),ve=m((()=>(0,s._)("br",null,null,-1))),xe=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"I implemented AAF based soft sahdow accroding to the paper: ",-1))),Ae=m((()=>(0,s._)("p",{style:{"text-align":"center"}},[(0,s._)("a",{href:"http://graphics.berkeley.edu/papers/UdayMehta-AAF-2012-12/"}," Axis-Aligned Filtering for Interactive Sampled Soft Shadows ")],-1))),ke=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"In our implementation, we estimate direct illumination as point light (as the original work and related works do, to ensure direct light part is not noisy). And we trace one primary ray with 9 shadow rays stratified on light source. Later, we also do up to 84 adaptive continue samples. Especially, we adopt a slope blur pass, before adaptive sampling, to remove some outliner points who failed to find any unoccluded path. We actually use max operator instead average which is mentioned in the paper. ",-1))),We=m((()=>(0,s._)("div",{id:"ssUnfiltFilt"},null,-1))),Fe=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: initial sample results | right: filtered result")],-1))),je=m((()=>(0,s._)("div",{id:"ssFiltGT"},null,-1))),Ie=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: filtered result | right: ground truth")],-1))),Se=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple-light"},null,-1))),Ue=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple"},null,-1))),Te=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"We can run AAF Soft Shadow in realtime with 300fps in 800X600. We use different random seed per frame and still get robust result without significant temporal anliasing. Here is a demo with animation: ",-1))),Ce=m((()=>(0,s._)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/jfqbPddvzgI",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1))),Re=m((()=>(0,s._)("h3",{id:"3.2. aafgi"},"3.2 AAF Global Illumination",-1))),Me=m((()=>(0,s._)("br",null,null,-1))),Ge=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"I implemented AAF based diffuse global illumination accroding to the paper: ",-1))),De=m((()=>(0,s._)("p",{style:{"text-align":"center"}},[(0,s._)("a",{href:"https://cseweb.ucsd.edu/~ravir/filtering_GI_final.pdf"}," Axis-Aligned Filtering for Interactive Physically-Based Diffuse Indirect Lighting ")],-1))),Ee=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"In our implementation, we use one bounce indirect lighting, 16 stratified initial samples and up to 84 adaptive continue samples for global illumination. No slope blur, and only do adaptive filtering on indirect light, which is later combined with direct light (use next event estimation). ",-1))),Pe=m((()=>(0,s._)("div",{id:"giUnfiltFilt"},null,-1))),Be=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: initial sample results | right: filtered result")],-1))),qe=m((()=>(0,s._)("div",{id:"giFiltGT"},null,-1))),Oe=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: filtered result | right: ground truth")],-1))),Le=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple-light"},null,-1))),ze=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple"},null,-1))),Ye=m((()=>(0,s._)("p",{style:{"text-align":"left"}},"We can run AAF GI in realtime with 60fps in 800X600. Again, we use different random seed per frame and get robust result without significant temporal anliasing. Here is a demo with animation: ",-1))),He=m((()=>(0,s._)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/U79zRqgjwy8",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1))),Ne=m((()=>(0,s._)("h3",{id:"3.3. MAAF"},"3.3 MAAF",-1))),Xe=m((()=>(0,s._)("br",null,null,-1))),Je=m((()=>(0,s._)("div",{id:"maaf1"},null,-1))),Ze=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: initial sample results | right: AAF filtered result")],-1))),Ve=m((()=>(0,s._)("div",{id:"maaf2"},null,-1))),Ke=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: AAF filtered result | right: ground truth")],-1))),Qe=m((()=>(0,s._)("div",{id:"maaf3"},null,-1))),$e=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: AAF filtered result | right: MAAF filtered result")],-1))),et=m((()=>(0,s._)("div",{id:"maaf4"},null,-1))),tt=m((()=>(0,s._)("p",null,[(0,s._)("code",null,"left: MAAF filtered result | right: ground truth")],-1))),it=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple-light"},null,-1))),lt=m((()=>(0,s._)("div",{class:"grid-content ep-bg-purple"},null,-1))),nt=m((()=>(0,s._)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/ER4TuurEvYM",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1))),at=m((()=>(0,s._)("h2",{id:"4. Application"},"4. Application Demo",-1))),st=m((()=>(0,s._)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/WleNYSftuv4",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""},null,-1))),ot=m((()=>(0,s._)("h2",{id:"Reference"},"Reference",-1))),rt=m((()=>(0,s._)("ol",null,[(0,s._)("li",{style:{"text-align":"left"}}," Soham Uday Mehta, Brandon Wang, and Ravi Ramamoorthi. 2012. Axis-aligned filtering for interactive sampled soft shadows. ACM Trans. Graph. 31, 6, Article 163 (November 2012), 10 pages. https://doi.org/10.1145/2366145.2366182 "),(0,s._)("li",{style:{"text-align":"left"}}," Soham Uday Mehta, Brandon Wang, Ravi Ramamoorthi, and Fredo Durand. 2013. Axis-aligned filtering for interactive physically-based diffuse indirect lighting. ACM Trans. Graph. 32, 4, Article 96 (July 2013), 12 pages. https://doi.org/10.1145/2461912.2461947 "),(0,s._)("li",{style:{"text-align":"left"}}," Soham Uday Mehta, JiaXian Yao, Ravi Ramamoorthi, and Fredo Durand. 2014. Factored axis-aligned filtering for rendering multiple distribution effects. ACM Trans. Graph. 33, 4, Article 57 (July 2014), 12 pages. https://doi.org/10.1145/2601097.2601113 "),(0,s._)("li",{style:{"text-align":"left"}}," Lifan Wu, Ling-Qi Yan, Alexandr Kuznetsov, and Ravi Ramamoorthi. 2017. Multiple Axis-Aligned Filters for Rendering of Combined Distribution Effects. Comput. Graph. Forum 36, 4 (July 2017), 155–166. https://doi.org/10.1111/cgf.13232 "),(0,s._)("li",{style:{"text-align":"left"}}," M. Zwicker, W. Jarosz, J. Lehtinen, B. Moon, R. Ramamoorthi, F. Rousselle, P. Sen, C. Soler, and S.-E. Yoon. 2015. Recent Advances in Adaptive Sampling and Reconstruction for Monte Carlo Rendering. Comput. Graph. Forum 34, 2 (May 2015), 667–681. ")],-1)));function ut(e,t,i,l,n,a){const o=(0,s.up)("el-header"),r=(0,s.up)("el-row"),u=(0,s.up)("vue-latex"),d=(0,s.up)("el-image"),f=(0,s.up)("el-col"),c=(0,s.up)("el-main"),m=(0,s.up)("el-divider"),ut=(0,s.up)("el-link"),dt=(0,s.up)("el-footer"),ft=(0,s.up)("el-container");return(0,s.wg)(),(0,s.iD)("div",h,[(0,s._)("div",p,[(0,s.Wm)(ft,null,{default:(0,s.w5)((()=>[(0,s.Wm)(ft,null,{default:(0,s.w5)((()=>[(0,s.Wm)(o,null,{default:(0,s.w5)((()=>[g])),_:1}),(0,s.Wm)(ft,null,{default:(0,s.w5)((()=>[(0,s.Wm)(ft,null,{default:(0,s.w5)((()=>[(0,s.Wm)(c,null,{default:(0,s.w5)((()=>[(0,s.Wm)(r,{class:"row-bg"},{default:(0,s.w5)((()=>[w,y,b])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[_,v,x])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[A])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[k,W])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[F,j])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[I,S])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[U,T,(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[C,R])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[M,(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[(0,s._)("li",G,[D,(0,s.Uk)(" For each primary ray shading point, find the distance to light (center) "),E,(0,s.Uk)(". Then emit multiple shadow ray from the shading point, who are stratified distributed on the light surface, collecting the minimum and maximum distance from light to any occluder along the ray, "),P,(0,s.Uk)(". The Fourier space slope is: "),(0,s.Wm)(u,{expression:"s=d_1/d_2-1","display-mode":""})]),(0,s._)("li",B,[q,(0,s.Uk)(" For each primary ray, emit multiple secondary rays from the shading point stratified distributed on the hemisphere, collecting the minimum and maximum distance "),O,(0,s.Uk)(" from shading point to any reflector. The Fourier space slope is: "),(0,s.Wm)(u,{expression:"s=z","display-mode":""})]),(0,s._)("li",L,[z,(0,s.Uk)(" Trace multiple primary rays on the lens, collecting the minimum and maximum depth "),Y,(0,s.Uk)(" of any hit objects. Also given the half-width of the image in pixels "),H,(0,s.Uk)(", the focal distance "),N,(0,s.Uk)(", the size of the focal plane "),X,(0,s.Uk)(". The Fourier space slope is: "),J,(0,s.Wm)(u,{expression:"s=\\frac{V}{S}(\\frac{F}{z}-1)","display-mode":""},null,8,["expression"]),(0,s.Uk)(" It is worth to notice that this slope value is also known as Circle of Confusion (CoC) in Depth of Field rendering. We know anything that's not at focus plane will projects to a region (instead of to a point) on the film. The diameter of this region is CoC and is exactly the Fourier space slope, but notice its sign will be different in foreground and background regions. "),(0,s.Wm)(u,{expression:"","display-mode":""})]),(0,s._)("li",Z,[V,(0,s.Uk)(" Trace multiple primary rays to collect surface minimum and maximum velocities "),K,(0,s.Uk)(". Different objects could have different velocities, one object does non-uniform motion could also have different velocities in the shutter period. The Fourier space slope is: "),(0,s.Wm)(u,{expression:"s=-a","display-mode":""})])])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Q,$])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[ee,(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[te,ie,le,ne])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[ae,se])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[oe,re])),_:1}),ue,(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[(0,s.Wm)(d,{style:{width:"400px",height:"300px"},src:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/gi-betta-cornellbox.png",fit:"fill"}),de])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[fe])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[(0,s.Wm)(d,{style:{width:"400px",height:"300px"},src:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/spp-gi-cornellbox.png",fit:"fill"}),ce])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[me,he,pe,ge,we])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[ye,be])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[_e,ve])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[xe])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[Ae])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[ke])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[(0,s.Wm)(f,{span:e.auto},{default:(0,s.w5)((()=>[We,Fe,je,Ie])),_:1},8,["span"]),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[Se])),_:1}),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[Ue])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Te])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[Ce])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Re,Me])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Ge])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[De])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Ee])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[(0,s.Wm)(f,{span:e.auto},{default:(0,s.w5)((()=>[Pe,Be,qe,Oe])),_:1},8,["span"]),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[Le])),_:1}),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[ze])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Ye])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[He])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[Ne,Xe])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[(0,s.Wm)(f,{span:e.auto},{default:(0,s.w5)((()=>[Je,Ze,Ve,Ke,Qe,$e,et,tt])),_:1},8,["span"]),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[it])),_:1}),(0,s.Wm)(f,{span:6},{default:(0,s.w5)((()=>[lt])),_:1})])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[nt])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[at])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"center"},{default:(0,s.w5)((()=>[st])),_:1}),(0,s.Wm)(r,{class:"row-bg",justify:"left"},{default:(0,s.w5)((()=>[ot,rt])),_:1})])),_:1}),(0,s.Wm)(m),(0,s.Wm)(dt,null,{default:(0,s.w5)((()=>[(0,s.Wm)(ut,{href:"https://suikasibyl.github.io/",target:"_blank",type:"primary"},{default:(0,s.w5)((()=>[(0,s.Uk)("My Homepage")])),_:1})])),_:1})])),_:1})])),_:1})])),_:1})])),_:1})])])}var dt=i(194),ft=i.n(dt),ct={name:"HomeView",mounted(){new(ft())({el:"#ssUnfiltFilt",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-noisy-softshadow-grids.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-filtered-softshadow-grids.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(ft())({el:"#ssFiltGT",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-filtered-softshadow-grids.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-benchmark-softshadow-grids.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(ft())({el:"#giUnfiltFilt",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-noisy-gi-cornellbox.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-filtered-gi-cornellbox.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(ft())({el:"#giFiltGT",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-filtered-gi-cornellbox.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/274denoiser-benchmark-gi-cornellbox.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(ft())({el:"#maaf1",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/maaf_input.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/maaf_AAF.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(ft())({el:"#maaf2",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/maaf_AAF.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/maaf_gt.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(ft())({el:"#maaf3",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/maaf_AAF.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/MAAF_maaf.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"}),new(ft())({el:"#maaf4",beforeImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/MAAF_maaf.png",afterImg:"https://imagehost-suikasibyl-us.oss-us-west-1.aliyuncs.com/maaf_gt.png",width:"90%",height:"400px",line:!0,lineColor:"rgba(0,0,0,0.1)"})}};const mt=(0,r.Z)(ct,[["render",ut],["__scopeId","data-v-8a92362a"]]);var ht=mt;const pt=[{path:"/CSE274-RealtimeDenoiser-WebPage/cse274-realtime-denoiser",name:"home",component:ht},{path:"/CSE274-RealtimeDenoiser-WebPage/about",name:"about",component:()=>i.e(443).then(i.bind(i,381))},{path:"/CSE274-RealtimeDenoiser-WebPage",redirect:"/CSE274-RealtimeDenoiser-WebPage/cse274-realtime-denoiser"},{path:"/",redirect:"/CSE274-RealtimeDenoiser-WebPage/cse274-realtime-denoiser"}],gt=(0,c.p7)({history:(0,c.PO)(""),routes:pt});var wt=gt;const yt=(0,l.ri)(f);yt.use(wt).mount("#app"),yt.use(n.Z),yt.use(a.ZP)}},t={};function i(l){var n=t[l];if(void 0!==n)return n.exports;var a=t[l]={exports:{}};return e[l].call(a.exports,a,a.exports,i),a.exports}i.m=e,function(){var e=[];i.O=function(t,l,n,a){if(!l){var s=1/0;for(d=0;d<e.length;d++){l=e[d][0],n=e[d][1],a=e[d][2];for(var o=!0,r=0;r<l.length;r++)(!1&a||s>=a)&&Object.keys(i.O).every((function(e){return i.O[e](l[r])}))?l.splice(r--,1):(o=!1,a<s&&(s=a));if(o){e.splice(d--,1);var u=n();void 0!==u&&(t=u)}}return t}a=a||0;for(var d=e.length;d>0&&e[d-1][2]>a;d--)e[d]=e[d-1];e[d]=[l,n,a]}}(),function(){i.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return i.d(t,{a:t}),t}}(),function(){i.d=function(e,t){for(var l in t)i.o(t,l)&&!i.o(e,l)&&Object.defineProperty(e,l,{enumerable:!0,get:t[l]})}}(),function(){i.f={},i.e=function(e){return Promise.all(Object.keys(i.f).reduce((function(t,l){return i.f[l](e,t),t}),[]))}}(),function(){i.u=function(e){return"js/about.32ee39d8.js"}}(),function(){i.miniCssF=function(e){}}(),function(){i.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"===typeof window)return window}}()}(),function(){i.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)}}(),function(){var e={},t="cse274:";i.l=function(l,n,a,s){if(e[l])e[l].push(n);else{var o,r;if(void 0!==a)for(var u=document.getElementsByTagName("script"),d=0;d<u.length;d++){var f=u[d];if(f.getAttribute("src")==l||f.getAttribute("data-webpack")==t+a){o=f;break}}o||(r=!0,o=document.createElement("script"),o.charset="utf-8",o.timeout=120,i.nc&&o.setAttribute("nonce",i.nc),o.setAttribute("data-webpack",t+a),o.src=l),e[l]=[n];var c=function(t,i){o.onerror=o.onload=null,clearTimeout(m);var n=e[l];if(delete e[l],o.parentNode&&o.parentNode.removeChild(o),n&&n.forEach((function(e){return e(i)})),t)return t(i)},m=setTimeout(c.bind(null,void 0,{type:"timeout",target:o}),12e4);o.onerror=c.bind(null,o.onerror),o.onload=c.bind(null,o.onload),r&&document.head.appendChild(o)}}}(),function(){i.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})}}(),function(){i.p=""}(),function(){var e={143:0};i.f.j=function(t,l){var n=i.o(e,t)?e[t]:void 0;if(0!==n)if(n)l.push(n[2]);else{var a=new Promise((function(i,l){n=e[t]=[i,l]}));l.push(n[2]=a);var s=i.p+i.u(t),o=new Error,r=function(l){if(i.o(e,t)&&(n=e[t],0!==n&&(e[t]=void 0),n)){var a=l&&("load"===l.type?"missing":l.type),s=l&&l.target&&l.target.src;o.message="Loading chunk "+t+" failed.\n("+a+": "+s+")",o.name="ChunkLoadError",o.type=a,o.request=s,n[1](o)}};i.l(s,r,"chunk-"+t,t)}},i.O.j=function(t){return 0===e[t]};var t=function(t,l){var n,a,s=l[0],o=l[1],r=l[2],u=0;if(s.some((function(t){return 0!==e[t]}))){for(n in o)i.o(o,n)&&(i.m[n]=o[n]);if(r)var d=r(i)}for(t&&t(l);u<s.length;u++)a=s[u],i.o(e,a)&&e[a]&&e[a][0](),e[a]=0;return i.O(d)},l=self["webpackChunkcse274"]=self["webpackChunkcse274"]||[];l.forEach(t.bind(null,0)),l.push=t.bind(null,l.push.bind(l))}();var l=i.O(void 0,[998],(function(){return i(943)}));l=i.O(l)})();
//# sourceMappingURL=app.866cea9d.js.map